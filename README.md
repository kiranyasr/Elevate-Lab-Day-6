ğŸ“– Objective

The goal of this project is to implement K-Nearest Neighbors (KNN) for classification tasks using the Iris dataset.
We explore different values of K, evaluate the modelâ€™s performance, and visualize decision boundaries.

ğŸ› ï¸ Tools & Libraries

Python 3.11+

Scikit-learn

Pandas

Matplotlib

NumPy

ğŸ“‚ Project Structure
Elevate-Lab-Day-6/
â”‚â”€â”€ data/
â”‚   â””â”€â”€ Iris.csv              # Dataset
â”‚â”€â”€ src/
â”‚   â””â”€â”€ knn_workflow.py       # Main implementation
â”‚â”€â”€ requirements.txt          # Python dependencies
â”‚â”€â”€ README.md                 # Project documentation
â”‚â”€â”€ venv/                     # Virtual environment (optional)

âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone Project & Navigate
cd Elevate-Lab-Day-6

2ï¸âƒ£ Create Virtual Environment
python -m venv venv
venv\Scripts\activate   # For Windows
source venv/bin/activate  # For Mac/Linux

3ï¸âƒ£ Install Requirements
pip install -r requirements.txt

â–¶ï¸ Running the Code
python src/knn_workflow.py

ğŸ“Š Expected Output

Best K value with accuracy.

Final accuracy score.

Confusion Matrix.

Decision boundary visualization plot for first two features.

Example:

Best k: 1 with accuracy: 0.9666
Final Accuracy: 0.9666
Confusion Matrix:
 [[10  0  0]
 [ 0 10  0]
 [ 0  1  9]]

ğŸ–¼ï¸ Visualization

The script also generates a decision boundary plot:

Different regions represent different Iris classes.

Training points are overlaid for better understanding.

ğŸ”‘ Key Learning Outcomes

Data preprocessing (loading, normalization, train-test split).

KNN classification with Scikit-learn.

Hyperparameter tuning with different K values.

Model evaluation using accuracy & confusion matrix.

Visualizing decision boundaries for classification.